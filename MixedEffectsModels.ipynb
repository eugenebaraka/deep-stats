{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0c54c88",
   "metadata": {},
   "source": [
    "# Linear Mixed Effects Models (LMEM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebc1c1f",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e76a145",
   "metadata": {},
   "source": [
    "The traditional regression models assume independence between observations in the dataset. However, this assumption can be unrealistic IRL since we may have multiple observations per person over time, or observations that are obtained from a group of people that share characteristics that may influence the outcome. Here we can not use a linear or logistic regression to model the outcome. That's where mixed effects/hierarchical/multilevel/varying coefficient models come in. \n",
    "\n",
    "The random effects model where coefficients vary across clusters is\n",
    "\n",
    "$$\n",
    "Y_{ij} = \\beta_{0i} + \\beta_{1}X_{ij} + \\epsilon_{ij}\n",
    "$$\n",
    "\n",
    "In this model, i represents the cluster, j represents the observation within cluster, and $Y_{ij}$ is the outcome for cluster i's observation j. \n",
    "\n",
    "Also, for this specic model, the intercept was specified for each of the cluster and can be rewritten as \n",
    "\n",
    "$$\n",
    "\\beta_{0i} = \\beta_0 + u_i\n",
    "$$\n",
    "\n",
    "- $\\beta_0$ is the part of the intercept common to all clusters\n",
    "- $u_i$ is the part of the intercept specific to each cluster. This means that this the random variation in the outcome that is not explained by $\\beta_0$\n",
    "    - $u_i$ is assumed to be random, therefore the name \"random effect model\"\n",
    "    - It is also assumed to follow a normal distribution distribution with unknown variance\n",
    "    \n",
    "    $$\n",
    "    u_i \\sim N(0, \\sigma^2_{u})\n",
    "    $$\n",
    "\n",
    "The traditional linear regression model can be seen as a special casse of the mixed model where $u_i$ = 0 for all i\n",
    "\n",
    "Therefore, the random intercept model above, can be rewritten as follows for clarity: \n",
    "\n",
    "$$\n",
    "Y_{ij} = \\beta_{0} + u_i + \\beta_{1}X_{ij} + \\epsilon_{ij}\n",
    "$$\n",
    "\n",
    "- $\\epsilon_{ij}$ are the errors of the model and represent the random variation in the outcome that is not not explained by both the fixed and random effects. They are all assumed to be independent of each other. WHY? THEY CAN ALSO BE DEPENDENT? They are also assumed to follow a normal distribution with mean zero and unknown variance.\n",
    "\n",
    "$$\n",
    "\\epsilon_{ij} \\sim N(0, \\sigma^2_{\\epsilon})\n",
    "$$\n",
    "\n",
    "And finally, $\\epsilon_{ij}$ and $u_i$ are independent of each other. \n",
    "\n",
    "### Independence between $\\epsilon_{ij}$ and $u_i$\n",
    "\n",
    "The random variation in the response variable that is not explained by the fixed and random effects ($\\epsilon_{ij}$) is not related to the random variation among the clusters ( $u_i$). This means that knowing the value of one for a specific cluster $i$ does not provide any information about the size or the direction of the other.  This allows us to estimate the variances of the random effects and the residual errors separately, which is necessary for accurate inference\n",
    "\n",
    "Expectation of the outcome is the same as in the traditional linear regression model where\n",
    "\n",
    "$$\n",
    "E[Y_{ij}|X_{ij}] = \\beta_0 + \\beta_1X_{ij}\n",
    "$$\n",
    "\n",
    "while the varianc of the oucome, which is **marginal** over $u_i$ is\n",
    "\n",
    "$$\n",
    "Var[Y_{ij}|X_{ij}] = Var[u_i] + Var[\\epsilon_{ij}] \\\\\n",
    "                    = \\sigma^2_{u} + \\sigma^2_{\\epsilon}\n",
    "$$\n",
    "    - The variability of the observations is due to both the variability between clusters and the varition that is not explained by the model ($\\epsilon_{ij}$)\n",
    "    \n",
    "### Covariance between observations from the same cluster\n",
    "\n",
    "$$\n",
    "Cov(Y_{ij}, Y_{ik}) = Cov(u_i + \\epsilon_{ij}, u_i + \\epsilon_{ik}) \\\\\n",
    "                    = Cov(u_i, u_i) + Cov(u_i, \\epsilon_{ij}) + Cov(u_i, \\epsilon_{ik}) + Cov(\\epsilon_{ij}, \\epsilon_{ik})\n",
    "                    = Var(u_i) + 0 + 0 + 0\n",
    "                    = \\sigma^2_{u}\n",
    "$$\n",
    "\n",
    "This means that the correlation between two observations from the same cluster is not zero!! This is why we need a mixed model\n",
    "\n",
    "- This model describes the correlation between subjects in the same cluster\n",
    "- This is a random intercept model and it has the correlation that is constant for all pairs of observations within the clusters. May not be appropriate for some data (e.g., longitudinal data where we assume autocorrelation)\n",
    "- Under the traditional regression model, $u_i = 0$, implying that the observations within the same cluster are independent\n",
    "\n",
    "\n",
    "NOTE: VERIFY IF COVARIANCE BETWEEN CLUSTERS IS ZERO!\n",
    "\n",
    "The model above (random intercept) can be modified to include a cluster-specific slope $\\beta_{1i} = \\beta_1 + u_1i$: \n",
    "\n",
    "$$\n",
    "Y_{ij} = \\beta_{0i} + \\beta_{1i}X_{ij} + \\epsilon_{ij}\n",
    "$$\n",
    "\n",
    "Assumptions: \n",
    "- $\\epsilon_{ij}$ are all independent with $N(0, \\sigma^2_{\\epsilon}$\n",
    "- u's are all independent\n",
    "- $\\epsilon$'s are independent from u's\n",
    "- us can be set to be independent to each other or allowed to be correlated\n",
    "\n",
    "\n",
    "### Expectation, variance and covariance random interecept\n",
    "\n",
    "- Expectation\n",
    "$$\n",
    "E(Y_ij|X_ij) = \\beta_0 + \\beta_1*X_{ij}\n",
    "$$\n",
    "\n",
    "- Variance\n",
    "$$\n",
    "Var[Y_{ij}|X_ij] = \\sigma^2_{u0} + \\sigma^2_{u1}X^2_{ij} + \\sigma^2_{\\epsilon}\n",
    "$$\n",
    "\n",
    "This assumes independence between u's. it is complicated otherwise\n",
    "\n",
    "- Covariance within clusters (again, u's are independent in this case)\n",
    "\n",
    "$$\n",
    "Cov(Y_{ij}, Y_{ik}) = \\sigma^2_{u0} + X_{ij}X_{ik}\\sigma^2_{u1}\n",
    "$$\n",
    "\n",
    "- Covariance betwen clusters\n",
    "$$\n",
    "Cov(Y_{ij}, Y_{i'k}) = 0\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "- If we allow coefficients to vary, we may have correlations between random coefficients\n",
    "\n",
    "If $Cov(u_{0i}, u_{1i} $ < 0 suggests that if the intercept is low, the slope will be high and if it is positive it suggests that if the intercept is high, the slope will also be high.\n",
    "\n",
    "- We can also add more covariates in the model\n",
    "\n",
    "\n",
    "- $\\beta$'s are called fixed coefficients\n",
    "- $u$'s are random effects\n",
    "- $\\epsilon$'s are errors\n",
    "\n",
    "The model above can be summarized as\n",
    "\n",
    "$$\n",
    "Y_{ij} = X\\beta + Zu + \\epsilon\n",
    "$$\n",
    "\n",
    "where $X$ is the design matrix of the fixed effects, $\\beta$ is the vector of fixed effects, $Z$ is the design matrix of random effects, $u$ is the vector of random effects, and $\\epsilon$ is the error that is not accounted for by fixed and random effect. We want to estimate $\\beta$'s and $u$'s in the model\n",
    "\n",
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6b59f94",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching packages\u001b[22m ────────────────────────────────── tidyverse 1.3.2 ──\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.4.1     \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 1.0.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.2.0     \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.1.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.3.0     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.5.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 2.1.3     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 1.0.0\n",
      "── \u001b[1mConflicts\u001b[22m ───────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\n",
      "Attachement du package : ‘data.table’\n",
      "\n",
      "\n",
      "Les objets suivants sont masqués depuis ‘package:dplyr’:\n",
      "\n",
      "    between, first, last\n",
      "\n",
      "\n",
      "L'objet suivant est masqué depuis ‘package:purrr’:\n",
      "\n",
      "    transpose\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load libraries\n",
    "library(tidyverse)\n",
    "library(data.table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "682da01d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 6 × 11</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>obs</th><th scope=col>school</th><th scope=col>normexam</th><th scope=col>schgend</th><th scope=col>schavg</th><th scope=col>vr</th><th scope=col>intake</th><th scope=col>standLRT</th><th scope=col>sex</th><th scope=col>type</th><th scope=col>student</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>1</td><td>1</td><td> 0.2613242</td><td>mixed</td><td>0.1661752</td><td>mid 50%</td><td>bottom 25%</td><td> 0.6190592</td><td>F</td><td>Mxd</td><td>143</td></tr>\n",
       "\t<tr><td>2</td><td>1</td><td> 0.1340672</td><td>mixed</td><td>0.1661752</td><td>mid 50%</td><td>mid 50%   </td><td> 0.2058022</td><td>F</td><td>Mxd</td><td>145</td></tr>\n",
       "\t<tr><td>3</td><td>1</td><td>-1.7238820</td><td>mixed</td><td>0.1661752</td><td>mid 50%</td><td>top 25%   </td><td>-1.3645760</td><td>M</td><td>Mxd</td><td>142</td></tr>\n",
       "\t<tr><td>4</td><td>1</td><td> 0.9675862</td><td>mixed</td><td>0.1661752</td><td>mid 50%</td><td>mid 50%   </td><td> 0.2058022</td><td>F</td><td>Mxd</td><td>141</td></tr>\n",
       "\t<tr><td>5</td><td>1</td><td> 0.5443412</td><td>mixed</td><td>0.1661752</td><td>mid 50%</td><td>mid 50%   </td><td> 0.3711052</td><td>F</td><td>Mxd</td><td>138</td></tr>\n",
       "\t<tr><td>6</td><td>1</td><td> 1.7348992</td><td>mixed</td><td>0.1661752</td><td>mid 50%</td><td>bottom 25%</td><td> 2.1894372</td><td>M</td><td>Mxd</td><td>155</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 6 × 11\n",
       "\\begin{tabular}{lllllllllll}\n",
       " obs & school & normexam & schgend & schavg & vr & intake & standLRT & sex & type & student\\\\\n",
       " <dbl> & <dbl> & <dbl> & <chr> & <dbl> & <chr> & <chr> & <dbl> & <chr> & <chr> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 1 & 1 &  0.2613242 & mixed & 0.1661752 & mid 50\\% & bottom 25\\% &  0.6190592 & F & Mxd & 143\\\\\n",
       "\t 2 & 1 &  0.1340672 & mixed & 0.1661752 & mid 50\\% & mid 50\\%    &  0.2058022 & F & Mxd & 145\\\\\n",
       "\t 3 & 1 & -1.7238820 & mixed & 0.1661752 & mid 50\\% & top 25\\%    & -1.3645760 & M & Mxd & 142\\\\\n",
       "\t 4 & 1 &  0.9675862 & mixed & 0.1661752 & mid 50\\% & mid 50\\%    &  0.2058022 & F & Mxd & 141\\\\\n",
       "\t 5 & 1 &  0.5443412 & mixed & 0.1661752 & mid 50\\% & mid 50\\%    &  0.3711052 & F & Mxd & 138\\\\\n",
       "\t 6 & 1 &  1.7348992 & mixed & 0.1661752 & mid 50\\% & bottom 25\\% &  2.1894372 & M & Mxd & 155\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 6 × 11\n",
       "\n",
       "| obs &lt;dbl&gt; | school &lt;dbl&gt; | normexam &lt;dbl&gt; | schgend &lt;chr&gt; | schavg &lt;dbl&gt; | vr &lt;chr&gt; | intake &lt;chr&gt; | standLRT &lt;dbl&gt; | sex &lt;chr&gt; | type &lt;chr&gt; | student &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | 1 |  0.2613242 | mixed | 0.1661752 | mid 50% | bottom 25% |  0.6190592 | F | Mxd | 143 |\n",
       "| 2 | 1 |  0.1340672 | mixed | 0.1661752 | mid 50% | mid 50%    |  0.2058022 | F | Mxd | 145 |\n",
       "| 3 | 1 | -1.7238820 | mixed | 0.1661752 | mid 50% | top 25%    | -1.3645760 | M | Mxd | 142 |\n",
       "| 4 | 1 |  0.9675862 | mixed | 0.1661752 | mid 50% | mid 50%    |  0.2058022 | F | Mxd | 141 |\n",
       "| 5 | 1 |  0.5443412 | mixed | 0.1661752 | mid 50% | mid 50%    |  0.3711052 | F | Mxd | 138 |\n",
       "| 6 | 1 |  1.7348992 | mixed | 0.1661752 | mid 50% | bottom 25% |  2.1894372 | M | Mxd | 155 |\n",
       "\n"
      ],
      "text/plain": [
       "  obs school normexam   schgend schavg    vr      intake     standLRT   sex\n",
       "1 1   1       0.2613242 mixed   0.1661752 mid 50% bottom 25%  0.6190592 F  \n",
       "2 2   1       0.1340672 mixed   0.1661752 mid 50% mid 50%     0.2058022 F  \n",
       "3 3   1      -1.7238820 mixed   0.1661752 mid 50% top 25%    -1.3645760 M  \n",
       "4 4   1       0.9675862 mixed   0.1661752 mid 50% mid 50%     0.2058022 F  \n",
       "5 5   1       0.5443412 mixed   0.1661752 mid 50% mid 50%     0.3711052 F  \n",
       "6 6   1       1.7348992 mixed   0.1661752 mid 50% bottom 25%  2.1894372 M  \n",
       "  type student\n",
       "1 Mxd  143    \n",
       "2 Mxd  145    \n",
       "3 Mxd  142    \n",
       "4 Mxd  141    \n",
       "5 Mxd  138    \n",
       "6 Mxd  155    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load data\n",
    "exam = read_csv(\"./lmedata/exam.csv\", show_col_types = FALSE)\n",
    "setDT(exam)\n",
    "head(exam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07b0bad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "exam$school  <- as.factor(exam$school )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7081bd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>4059</li><li>11</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 4059\n",
       "\\item 11\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 4059\n",
       "2. 11\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 4059   11"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim(exam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4767676c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "65"
      ],
      "text/latex": [
       "65"
      ],
      "text/markdown": [
       "65"
      ],
      "text/plain": [
       "[1] 65"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "uniqueN(exam$school)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5863de2",
   "metadata": {},
   "source": [
    "- 4059 students in 65 schools\n",
    "- Exam scores - one exam per student\n",
    "- Correlation - If there are “high-performing” schools, maybe kids in\n",
    "these schools are more alike\n",
    "- Outcome: 16 year reading test score\n",
    "- Covariates:\n",
    "    - Sex\n",
    "    - 11 year reading test score\n",
    "    - School sex (mixed, boys, girls)\n",
    "    - School average score\n",
    "- All scores are standardized\n",
    "\n",
    "## Fit model with just standLTR as a predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31230c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Vi(Zi, D, Ri):\n",
    "    \"\"\"\n",
    "    Computes the variance-covariance structure of the repeated\n",
    "    observations within cohort i\n",
    "    \"\"\"\n",
    "    Vi = np.matmul(Zi, D)\n",
    "    Vi = np.matmul(Vi, np.transpose(Zi)) + Ri\n",
    "    return Vi\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "670f1b67",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in X %*% beta: arguments inadéquats\n",
     "output_type": "error",
     "traceback": [
      "Error in X %*% beta: arguments inadéquats\nTraceback:\n",
      "1. optim(c(beta, u), logLikelihood, method = \"L-BFGS-B\", lower = c(-Inf, \n .     rep(-Inf, nlevels(exam$school))), upper = c(Inf, rep(Inf, \n .     nlevels(exam$school))))",
      "2. (function (par) \n . fn(par, ...))(c(0, 0, -2.07939836030236, -1.69702733859689, -0.284148126280274, \n . 0.476737494160306, 1.18127544282294, 1.22212053291203, 0.793481719772765, \n . 1.40006439217067, -1.11398227542666, -2.55968743001956, -0.343675014807025, \n . 0.291577892302924, -0.764336785723951, 1.25528710856104, -1.00793352726225, \n . 1.81303179103786, 0.206191328810182, 0.786282186205487, -1.64151349316327, \n . -2.18227261001051, -0.154652775399499, 1.77630927042212, -2.27995787509891, \n . -0.0786833724119287, -0.0880570448297088, -0.08658440034333, \n . 0.140109797822219, -0.508785258914841, -1.22650084648888, -0.059429816474282, \n . 0.664168822132148, 0.0969834175612353, -1.22035786846218, 0.00665880789358308, \n . -0.847734787875118, -0.627222989562702, 0.431147009849378, 0.272479553512831, \n . 0.906028530065211, 2.6522104098383, -0.329513519423573, 0.83815504567465, \n . -0.123451299365248, 0.154281943314297, 0.733962908912481, -0.703939393265348, \n . 0.98371950942603, 1.49155411112089, -0.151699143929734, -0.91842371719497, \n . 0.42183653530165, -0.93455933587308, 0.982224584517683, -0.391207601937963, \n . -0.264029448733104, -0.209540706106116, -0.475603124980885, -0.414805324568038, \n . 0.440172623604569, -0.494348047927234, -0.426243640147443, 0.389785139511327, \n . 1.97064953635889, 0.837555503025079, 0.0633397531614985))",
      "3. fn(par, ...)"
     ]
    }
   ],
   "source": [
    "# define variance-covariance structure\n",
    "\n",
    "get_Vi  <- function(Zi, D, Ri){\n",
    "    Vi  <- Zi %*% D\n",
    "    Vi  <- Vi %*% t(Zi) + Ri\n",
    "    \n",
    "    return(Vi)\n",
    "}\n",
    "\n",
    "\n",
    "get_MLE_beta  <- function(Xi_list, yi_list, Vi_list){\n",
    "    \n",
    "    p = dim(Xi_list[0])[2]\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_mle_beta(Xi_list, yi_list, Vi_list):\n",
    "    \"\"\"\n",
    "    Computes the MLE for beta\n",
    "    \"\"\"\n",
    "    p = Xi_list[0].shape[1]\n",
    "    \n",
    "    mat1 = np.zeros((p, p))\n",
    "    mat2 = np.zeros(p)\n",
    "    \n",
    "    for i in range(len(Xi_list)):\n",
    "        e\n",
    "        Xi = Xi_list[i]\n",
    "        yi = yi_list[i]\n",
    "        Vi = Vi_list[i]\n",
    "        \n",
    "        m1 = np.matmul(np.transpose(Xi), np.linalg.inv(Vi))\n",
    "        m1 = np.matmul(m1, Xi)\n",
    "        \n",
    "        m2 = np.matmul(np.transpose(Xi), np.linalg.inv(Vi))\n",
    "        m2 = np.matmul(m2, yi)\n",
    "        \n",
    "        mat1 += m1\n",
    "        mat2 += m2\n",
    "        \n",
    "    # MLE estimates for beta\n",
    "    beta = np.matmul(np.linalg.inv(mat1), mat2)\n",
    "    return beta\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# specify design matrix \n",
    "X  <-  model.matrix(~1+standLRT, data = exam) # fixed effects design matrix\n",
    "Z  <-  model.matrix(~1+school, data = exam) # random effects design matrix\n",
    "y  <- exam$normexam\n",
    "\n",
    "# model formula\n",
    "formula  <- y ~ X %*% beta + Z %*% u\n",
    "\n",
    "# specify initial values for fixed and random effects\n",
    "beta  <- rep(0, ncol(X))\n",
    "u  <- rnorm(nlevels(exam$school))\n",
    "\n",
    "# define the log-likelihood function\n",
    "logLikelihood  <- function(beta, u) {\n",
    "    theta  <- X %*% beta + Z %*% u\n",
    "    sigma  <- exp(theta)\n",
    "    -sum(dnorm(y, theta, sigma, log = TRUE))\n",
    "}\n",
    "\n",
    "# maximize the log-likelihood function\n",
    "fit  <- optim(c(beta, u), logLikelihood, method = \"L-BFGS-B\", \n",
    "              lower = c(-Inf, rep(-Inf, nlevels(exam$school))), \n",
    "              upper = c(Inf, rep(Inf, nlevels(exam$school))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f3d578",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d6ba88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Specify the design matrices and vectors\n",
    "X <- model.matrix(~1+Days, data = sleepstudy)  # Fixed effects design matrix\n",
    "Z <- model.matrix(~1+Subject, data = sleepstudy)  # Random effects design matrix\n",
    "y <- sleepstudy$Reaction  # Response vector\n",
    "\n",
    "# Specify the model formula\n",
    "formula <- y ~ X %*% beta + Z %*% u\n",
    "\n",
    "# Specify the initial values for the fixed and random effects\n",
    "beta <- rep(0, ncol(X))\n",
    "u <- rnorm(nlevels(sleepstudy$Subject))\n",
    "\n",
    "# Define the log-likelihood function\n",
    "logLikelihood <- function(beta, u) {\n",
    "  eta <- X %*% beta + Z %*% u\n",
    "  sigma <- exp(theta)\n",
    "  -sum(dnorm(y, eta, sigma, log = TRUE))\n",
    "}\n",
    "\n",
    "# Maximize the log-likelihood function\n",
    "fit <- optim(c(beta, u), logLikelihood, method = \"L-BFGS-B\", lower = c(-Inf, rep(-Inf, nlevels(sleepstudy$Subject))), upper = c(Inf, rep(Inf, nlevels(sleepstudy$Subject))))\n",
    "\n",
    "# Extract the coefficients\n",
    "beta_hat <- fit$par[1:ncol(X)]\n",
    "u_hat <- fit$par[(ncol(X)+1):length(fit$par)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "r"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
